<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="tags: #ðŸ—ƒ/ðŸŸ¥ aliases: ref: https://www.youtube.com/watch?v=MnT1xgZgkpk&ab_channel=TED
Think about if Earth was created one year ago,the human species, then, would be 10 minutes old."><meta property="og:title" content><meta property="og:description" content="tags: #ðŸ—ƒ/ðŸŸ¥ aliases: ref: https://www.youtube.com/watch?v=MnT1xgZgkpk&ab_channel=TED
Think about if Earth was created one year ago,the human species, then, would be 10 minutes old."><meta property="og:type" content="website"><meta property="og:image" content="https://dans-huang.github.io/Add-Lightness/icon.png"><meta property="og:url" content="https://dans-huang.github.io/Add-Lightness/Research//Catastrophic-Risk/What-Happens-When-Our-Computers-Get-Smarter-Than-We-Are-Nick-Bostrom/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="tags: #ðŸ—ƒ/ðŸŸ¥ aliases: ref: https://www.youtube.com/watch?v=MnT1xgZgkpk&ab_channel=TED
Think about if Earth was created one year ago,the human species, then, would be 10 minutes old."><meta name=twitter:image content="https://dans-huang.github.io/Add-Lightness/icon.png"><meta name=twitter:site content="dans_huang"><title>Add Lightness</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" href=icon.png type=image/png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link href=https://dans-huang.github.io/Add-Lightness/styles.7ff8be795f90cf8edaddadbffc4bf20e.min.css rel=stylesheet><link href=https://dans-huang.github.io/Add-Lightness/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://dans-huang.github.io/Add-Lightness/js/darkmode.130f627e6fb04d544d2555445005c010.min.js></script>
<script src=https://dans-huang.github.io/Add-Lightness/js/util.a0ccf91e1937fe761a74da4946452710.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script async src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script async src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script async src=https://dans-huang.github.io/Add-Lightness/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://dans-huang.github.io/Add-Lightness/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://dans-huang.github.io/Add-Lightness/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://dans-huang.github.io/Add-Lightness/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://dans-huang.github.io/Add-Lightness/",fetchData=Promise.all([fetch("https://dans-huang.github.io/Add-Lightness/indices/linkIndex.eede313bc6ffa231d47a92a511d2ecf4.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://dans-huang.github.io/Add-Lightness/indices/contentIndex.7f306907903b163f0f9daf5d32f481bd.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://dans-huang.github.io/Add-Lightness",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!0;drawGraph("https://dans-huang.github.io/Add-Lightness",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(e){const t=e.target,n=t.className.split(" "),s=n.includes("broken"),o=n.includes("internal-link");plausible("Link Click",{props:{href:t.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{"â€™":"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/dans-huang.github.io\/Add-Lightness\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=dans-huang.github.io/Add-Lightness src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://dans-huang.github.io/Add-Lightness/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://dans-huang.github.io/Add-Lightness/>Add Lightness</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown</p><ul class=tags></ul><p>tags: #ðŸ—ƒ/ðŸŸ¥
aliases:
ref:
<a href="https://www.youtube.com/watch?v=MnT1xgZgkpk&ab_channel=TED" rel=noopener>https://www.youtube.com/watch?v=MnT1xgZgkpk&ab_channel=TED</a></p><hr><ul><li>Think about if Earth was created one year ago,the human species, then, would be 10 minutes old.The industrial era started two seconds ago. (
<a href=https://read.readwise.io/read/01gqyjda0w4f9rbb2gx3qgxape rel=noopener>View Highlight</a>)</li><li>A couple of years ago,we did a survey of some of the world&rsquo;s leading A.I. experts,
to see what they think, and one of the questions we asked was,&ldquo;By which year do you think there is a 50 percent probabilitythat we will have achieved human-level machine intelligence?&rdquo; (
<a href=https://read.readwise.io/read/01gqyjs1e0etnzcsr6wnpwz72g rel=noopener>View Highlight</a>)</li><li>And the median answer was 2040 or 2050,depending on precisely which group of experts we asked. (
<a href=https://read.readwise.io/read/01gqyjs81ek0hdez4t49g9jd74 rel=noopener>View Highlight</a>)</li><li>What we do know is that the ultimate limit to information processingin a machine substrate lies far outside the limits in biological tissue. (
<a href=https://read.readwise.io/read/01gqyjskhx53w8f8291pv8vm62 rel=noopener>View Highlight</a>)</li><li>So the potential for superintelligence lies dormant in matter,much like the power of the atom lay dormant throughout human history,patiently waiting there until 1945.
In this century,scientists may learn to awaken the power of artificial intelligence.And I think we might then see an intelligence explosion. (
<a href=https://read.readwise.io/read/01gqyjtrf8az2h81dzna4e1hb7 rel=noopener>View Highlight</a>)</li><li>Once there is superintelligence,the fate of humanity may depend on what the superintelligence does.Think about it:Machine intelligence is the last invention that humanity will ever need to make.Machines will then be better at inventing than we are,and they&rsquo;ll be doing so on digital timescales. (
<a href=https://read.readwise.io/read/01gqyjyn3s0mr65jvb91vnywwa rel=noopener>View Highlight</a>)</li><li>What this means is basically a telescoping of the future.
Think of all the crazy technologies that you could have imaginedmaybe humans could have developed in the fullness of time:cures for aging, space colonization,self-replicating nanobots or uploading of minds into computers,all kinds of science fiction-y stuffthat&rsquo;s nevertheless consistent with the laws of physics.All of this superintelligence could develop, and possibly quite rapidly. (
<a href=https://read.readwise.io/read/01gqyjywv63k2gz43t9a9dn6g9 rel=noopener>View Highlight</a>)</li><li>Now, a superintelligence with such technological maturitywould be extremely powerful,
and at least in some scenarios, it would be able to get what it wants.We would then have a future that would be shaped by the preferences of this A.I. (
<a href=https://read.readwise.io/read/01gqyjz89da8rvms4qtwq7z62y rel=noopener>View Highlight</a>)</li><li>Now a good question is, what are those preferences? (
<a href=https://read.readwise.io/read/01gqyjzf43w8ed2g41p007ncjj rel=noopener>View Highlight</a>)</li><li>We need to think of intelligence as an optimization process,a process that steers the future into a particular set of configurations.A superintelligence is a really strong optimization process.It&rsquo;s extremely good at using available means to achieve a statein which its goal is realized.This means that there is no necessary connection between
being highly intelligent in this sense,and having an objective that we humans would find worthwhile or meaningful. (
<a href=https://read.readwise.io/read/01gqyk0kpxjxt9peg7h7xvh9bm rel=noopener>View Highlight</a>)</li><li>if you create a really powerful optimization processto maximize for objective x,you better make sure that your definition of xincorporates everything you care about. (
<a href=https://read.readwise.io/read/01gqyk46hqvqt5en43kjrm9fnx rel=noopener>View Highlight</a>)</li><li>This is a lesson that&rsquo;s also taught in many a myth.King Midas wishes that everything he touches be turned into gold.He touches his daughter, she turns into gold.He touches his food, it turns into gold.
This could become practically relevant,not just as a metaphor for greed,but as an illustration of what happensif you create a powerful optimization processand give it misconceived or poorly specified goals. (
<a href=https://read.readwise.io/read/01gqyk5532eh9zvakez72cfs22 rel=noopener>View Highlight</a>)</li><li>The point here is that we should not be confident in our abilityto keep a superintelligent genie locked up in its bottle forever.Sooner or later, it will out. (
<a href=https://read.readwise.io/read/01gqykgnen6na6gcwrk0jw7mhs rel=noopener>View Highlight</a>)</li><li>I believe that the answer here is to figure out
how to create super intelligent A.I. such that even if &ndash; when &ndash; it escapes, it is still safe because it is fundamentally on our side because it shares our values. I see no way around this difficult problem. (
<a href=https://read.readwise.io/read/01gqykh58mfrazsjymrgmg606m rel=noopener>View Highlight</a>)</li><li>Instead, we would create an A.I. that uses its intelligence to learn what we value, and its motivation system is constructed in such a way that it is motivated to pursue our values or to perform actions that it predicts we would approve of. We would thus leverage its intelligence as much as possible to solve the problem of value-loading. (
<a href=https://read.readwise.io/read/01gqykja6pnvxd0a8y5by5yaqg rel=noopener>View Highlight</a>)</li><li>The initial conditions for the intelligence explosion might need to be set up in just the right way if we are to have a controlled detonation. The values that the A.I. has need to match ours, not just in the familiar context, like where we can easily check how the A.I. behaves, but also in all novel contexts that the A.I. might encounter in the indefinite future. And there are also some esoteric issues that would need to be solved, sorted out: the exact details of its decision theory,
how to deal with logical uncertainty and so forth. (
<a href=https://read.readwise.io/read/01gqykntbnmjajhrtmq589xptm rel=noopener>View Highlight</a>)</li><li>Here is the worry: Making super intelligent A.I. is a really hard challenge. Making super intelligent A.I. that is safe involves some additional challenge on top of that. The risk is that if somebody figures out how to crack the first challenge
without also having cracked the additional challenge of ensuring perfect safety. (
<a href=https://read.readwise.io/read/01gqykpkh45wd722xnspbc5vs1 rel=noopener>View Highlight</a>)</li><li>I think that we should work out a solution to the control problem in advance, so that we have it available by the time it is needed. Now it might be that we cannot solve the entire control problem in advance because maybe some elements can only be put in place once you know the details of the architecture where it will be implemented. But the more of the control problem that we solve in advance,
the better the odds that the transition to the machine intelligence era will go well. (
<a href=https://read.readwise.io/read/01gqykq976e22hmqea6j2k4f5w rel=noopener>View Highlight</a>)</li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://dans-huang.github.io/Add-Lightness/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Dans Huang using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2023</p><ul><li><a href=https://dans-huang.github.io/Add-Lightness/>Home</a></li><li><a href=https://twitter.com/dans_huang>Twitter</a></li></ul></footer></div></div></body></html>