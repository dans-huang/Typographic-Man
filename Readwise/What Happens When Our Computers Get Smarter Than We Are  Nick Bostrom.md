#ðŸ—ƒ/ðŸŸ¥ 
ref: 
https://www.youtube.com/watch?v=MnT1xgZgkpk&ab_channel=TED

---

- Think about if Earth was created one year ago,the human species, then, would be 10 minutes old.The industrial era started two seconds ago. ([View Highlight](https://read.readwise.io/read/01gqyjda0w4f9rbb2gx3qgxape))
- A couple of years ago,we did a survey of some of the world's leading A.I. experts,
  to see what they think, and one of the questions we asked was,"By which year do you think there is a 50 percent probabilitythat we will have achieved human-level machine intelligence?" ([View Highlight](https://read.readwise.io/read/01gqyjs1e0etnzcsr6wnpwz72g))
- And the median answer was 2040 or 2050,depending on precisely which group of experts we asked. ([View Highlight](https://read.readwise.io/read/01gqyjs81ek0hdez4t49g9jd74))
- What we do know is that the ultimate limit to information processingin a machine substrate lies far outside the limits in biological tissue. ([View Highlight](https://read.readwise.io/read/01gqyjskhx53w8f8291pv8vm62))
- So the potential for superintelligence lies dormant in matter,much like the power of the atom lay dormant throughout human history,patiently waiting there until 1945.
  In this century,scientists may learn to awaken the power of artificial intelligence.And I think we might then see an intelligence explosion. ([View Highlight](https://read.readwise.io/read/01gqyjtrf8az2h81dzna4e1hb7))
- Once there is superintelligence,the fate of humanity may depend on what the superintelligence does.Think about it:Machine intelligence is the last invention that humanity will ever need to make.Machines will then be better at inventing than we are,and they'll be doing so on digital timescales. ([View Highlight](https://read.readwise.io/read/01gqyjyn3s0mr65jvb91vnywwa))
- What this means is basically a telescoping of the future.
  Think of all the crazy technologies that you could have imaginedmaybe humans could have developed in the fullness of time:cures for aging, space colonization,self-replicating nanobots or uploading of minds into computers,all kinds of science fiction-y stuffthat's nevertheless consistent with the laws of physics.All of this superintelligence could develop, and possibly quite rapidly. ([View Highlight](https://read.readwise.io/read/01gqyjywv63k2gz43t9a9dn6g9))
- Now, a superintelligence with such technological maturitywould be extremely powerful,
  and at least in some scenarios, it would be able to get what it wants.We would then have a future that would be shaped by the preferences of this A.I. ([View Highlight](https://read.readwise.io/read/01gqyjz89da8rvms4qtwq7z62y))
- Now a good question is, what are those preferences? ([View Highlight](https://read.readwise.io/read/01gqyjzf43w8ed2g41p007ncjj))
- We need to think of intelligence as an optimization process,a process that steers the future into a particular set of configurations.A superintelligence is a really strong optimization process.It's extremely good at using available means to achieve a statein which its goal is realized.This means that there is no necessary connection between
  being highly intelligent in this sense,and having an objective that we humans would find worthwhile or meaningful. ([View Highlight](https://read.readwise.io/read/01gqyk0kpxjxt9peg7h7xvh9bm))
- if you create a really powerful optimization processto maximize for objective x,you better make sure that your definition of xincorporates everything you care about. ([View Highlight](https://read.readwise.io/read/01gqyk46hqvqt5en43kjrm9fnx))
- This is a lesson that's also taught in many a myth.King Midas wishes that everything he touches be turned into gold.He touches his daughter, she turns into gold.He touches his food, it turns into gold.
  This could become practically relevant,not just as a metaphor for greed,but as an illustration of what happensif you create a powerful optimization processand give it misconceived or poorly specified goals. ([View Highlight](https://read.readwise.io/read/01gqyk5532eh9zvakez72cfs22))
- The point here is that we should not be confident in our abilityto keep a superintelligent genie locked up in its bottle forever.Sooner or later, it will out. ([View Highlight](https://read.readwise.io/read/01gqykgnen6na6gcwrk0jw7mhs))
- I believe that the answer here is to figure out
  how to create superintelligent A.I. such that even if -- when -- it escapes,it is still safe because it is fundamentally on our sidebecause it shares our values.I see no way around this difficult problem. ([View Highlight](https://read.readwise.io/read/01gqykh58mfrazsjymrgmg606m))
- Instead, we would create an A.I. that uses its intelligenceto learn what we value,and its motivation system is constructed in such a way that it is motivatedto pursue our values or to perform actions that it predicts we would approve of.We would thus leverage its intelligence as much as possibleto solve the problem of value-loading. ([View Highlight](https://read.readwise.io/read/01gqykja6pnvxd0a8y5by5yaqg))
- The initial conditions for the intelligence explosionmight need to be set up in just the right wayif we are to have a controlled detonation.The values that the A.I. has need to match ours,not just in the familiar context,like where we can easily check how the A.I. behaves,but also in all novel contexts that the A.I. might encounterin the indefinite future.And there are also some esoteric issues that would need to be solved, sorted out:the exact details of its decision theory,
  how to deal with logical uncertainty and so forth. ([View Highlight](https://read.readwise.io/read/01gqykntbnmjajhrtmq589xptm))
- Here is the worry:Making superintelligent A.I. is a really hard challenge.Making superintelligent A.I. that is safeinvolves some additional challenge on top of that.The risk is that if somebody figures out how to crack the first challenge
  without also having cracked the additional challengeof ensuring perfect safety. ([View Highlight](https://read.readwise.io/read/01gqykpkh45wd722xnspbc5vs1))
- I think that we should work out a solutionto the control problem in advance,so that we have it available by the time it is needed.Now it might be that we cannot solve the entire control problem in advancebecause maybe some elements can only be put in placeonce you know the details of the architecture where it will be implemented.But the more of the control problem that we solve in advance,
  the better the odds that the transition to the machine intelligence erawill go well. ([View Highlight](https://read.readwise.io/read/01gqykq976e22hmqea6j2k4f5w))
